// Copyright 2022 Ben L. Titzer. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

var config_TrackFloatZeroConst = false;
def INITIAL = 16;
def OUT = Trace.OUT;
def regRefCounts = Array<int>.new(128);

// Expose constants outside this file.
component SpcConsts {
	// Abstract values tracked during single-pass compilation.
	def NO_REG = Reg(0);
	def IS_STORED: byte = 0x01;
	def IS_CONST: byte = 0x02;
	def IN_REG: byte = 0x04;
	def TAG_STORED: byte = 0x08;
	def KIND_MASK: byte = 0xF0;
	def KIND_I32: byte = kindToFlags(ValueKind.I32);
	def KIND_I64: byte = kindToFlags(ValueKind.I64);
	def KIND_F32: byte = kindToFlags(ValueKind.F32);
	def KIND_F64: byte = kindToFlags(ValueKind.F64);
	def KIND_V128: byte = kindToFlags(ValueKind.V128);
	def KIND_REF: byte = kindToFlags(ValueKind.REF);
	def KIND_ABS: byte = kindToFlags(ValueKind.ABS);
	def kinds: Array<ValueKind> = [ValueKind.I32, ValueKind.I64, ValueKind.F32, ValueKind.F64,
					ValueKind.V128, ValueKind.REF, ValueKind.ABS];
	def kindToFlags(kind: ValueKind) -> byte {
		return byte.view(kind.tag) << 4;
	}
}

// Shorten constants inside this file.
def NO_REG = SpcConsts.NO_REG;
def IS_STORED = SpcConsts.IS_STORED;
def IS_CONST = SpcConsts.IS_CONST;
def IN_REG = SpcConsts.IN_REG;
def TAG_STORED = SpcConsts.TAG_STORED;
def KIND_MASK = SpcConsts.KIND_MASK;
def KIND_I32 = SpcConsts.KIND_I32;
def KIND_I64 = SpcConsts.KIND_I64;
def KIND_F32 = SpcConsts.KIND_F32;
def KIND_F64 = SpcConsts.KIND_F64;
def KIND_V128 = SpcConsts.KIND_V128;
def KIND_REF = SpcConsts.KIND_REF;
def KIND_ABS = SpcConsts.KIND_ABS;

// Compiles Wasm bytecode to machine code in a single pass via a MacroAssembler.
class SinglePassCompiler(masm: MacroAssembler, extensions: Extension.set, limits: Limits, module: Module) extends BytecodeVisitor {
	def err = ErrorGen.new(module.name);
	def it = BytecodeIterator.new();
	def instrTracer = if(Trace.compiler, InstrTracer.new());
	def regs = masm.regAlloc.regConfig.regs;

	// Abstract state of the value stack
	def state = SpcAbstractState.new(masm.regAlloc);
	// Other state
	var start_pos = 0;
	var func: FuncDecl;
	var sig: SigDecl;
	var success = true;
	var unwind_label: MasmLabel;
	var last_probe = 0;
	var skip_to_end: bool;

	new() {
		masm.unimplemented = unsupported;
		var c = masm.regAlloc.regConfig;
		masm.scratchStackSlot1 = c.eip_offset;
		masm.scratchStackSlot2 = c.stp_offset;
	}

	def gen(func: FuncDecl) -> bool {
		if (Trace.compiler) OUT.put1("==== begin compile: %q ========================", func.render(module.names, _)).outln();
		this.func = func;
		it.reset(func);

		sig = func.sig;
		unwind_label = null;
		masm.regAlloc.clear();
		success = true;

		// Initialize parameters, locals, and first control stack entry.
		var ret_label = masm.newLabel(func.cur_bytecode.length);
		state.reset(sig, ret_label);

		// Visit all local declarations.
		it.dispatchLocalDecls(this);

		// Emit prologue, which allocates the frame and initializes various registers.
		emitPrologue();

		// Emit instructions.
		while (it.more() && success) {
			if (Trace.compiler) traceOpcodeAndStack();
			last_probe = 0;
			it.dispatch(this);
			if (Debug.compiler) checkRegAlloc();
			it.next();
			if (skip_to_end) doSkipToEndOfBlock();
		}
		return success;
	}
	def doSkipToEndOfBlock() {
		skip_to_end = false;
		var height = 0;
		while (it.more() && success) {
			var opcode = it.current();
			match (opcode) {
				BLOCK, LOOP, TRY, IF => height++;
				ELSE, CATCH, CATCH_ALL => if (height == 0) return;
				END, DELEGATE => if (height-- == 0) return;
				_ => ;
			}
			if (Trace.compiler) traceOpcodeUnreachable();
			it.next();
		}
	}
	def checkRegAlloc() {
		if (Trace.compiler) {
			OUT.puts("checkRegAlloc ");
			traceStack();
		}
		for (i < regRefCounts.length) regRefCounts[i] = 0;
		var c = masm.regAlloc.regConfig;
		for (i < state.sp) {
			var sv = state.state[i];
			if (sv.inReg())  {
				var ri = sv.reg.index;
				assert1(ri != 0, "state[%d].inReg but reg == 0", i);
				assert1(ri < c.regSet.length, "state[%d], has invalid register", i);
				var pool = c.regToPool[ri];
				assert1(pool >= 0 && pool < c.numRegPools, "state[%d] has invalid register pool", i);
				var poolk = c.kindToPool[sv.kind().tag];
				assert1(pool == poolk, "state[%d] differs on pool membership", i);
				regRefCounts[ri]++;
			}
		}
		for (i = 1; i < c.regSet.length; i++) {
			var r = Reg(byte.view(i));
			if (regRefCounts[i] == 0) assert1(masm.regAlloc.isFree(r), "%s should be free", c.regSet.getName(r));
			else assert1(!masm.regAlloc.isFree(Reg(byte.view(i))), "%s should be allocated", c.regSet.getName(r));
		}
	}
	def assert1<T>(cond: bool, msg: string, param: T) {
		if (!cond) bailout(Strings.format1(msg, param));
	}
	def emitPrologue() {
		var c = masm.regAlloc.regConfig;

		var offsets = masm.getOffsets();
		// Allocate stack frame
		masm.emit_subw_r_i(regs.sp, c.spcFrameSize);

		// Spill VSP
		masm.emit_mov_m_r(MasmAddr(regs.sp, c.vsp_offset), regs.vsp, ValueKind.REF); // XXX: track VSP-spilled state
		// Spill wf: WasmFunction
		masm.emit_mov_m_r(MasmAddr(regs.sp, c.wasm_func_offset), regs.func_arg, ValueKind.REF);
		// Load wf.instance and spill
		masm.emit_mov_r_m(regs.instance, ValueKind.REF, MasmAddr(regs.func_arg, offsets.WasmFunction_instance));
		masm.emit_mov_m_r(MasmAddr(regs.sp, c.instance_offset), regs.instance, ValueKind.REF);
		// Clear FrameAccessor
		masm.emit_mov_m_l(MasmAddr(regs.sp, c.accessor_offset), 0); // XXX: value kind

		// Compute VFP = VSP - sig.params.length * SLOT_SIZE
		masm.emit_mov_r_r(regs.vfp, regs.vsp); // XXX: use 3-addr adjustment of VFP
		masm.emit_subw_r_i(regs.vfp, sig.params.length * masm.valuerep.slot_size);
		// XXX: skip spilling of VFP
		masm.emit_mov_m_r(MasmAddr(regs.sp, c.vfp_offset), regs.vfp, ValueKind.REF);

		// Load instance.memories[0].start into MEM0_BASE and spill
		if (module.memories.length > 0) {
			// XXX: skip loading memory base if function doesn't access memory
			masm.emit_mov_r_m(regs.mem0, ValueKind.REF, MasmAddr(regs.instance, offsets.Instance_memories));
			masm.emit_read_v3_array_r_i(regs.mem0, regs.mem0, 0, ValueKind.REF);
			masm.emit_read_v3_mem_base(regs.mem0, regs.mem0);
			masm.emit_mov_m_r(MasmAddr(regs.sp, c.mem_offset), regs.mem0, ValueKind.REF);
		}
	}
	def visitLocalDecl(count: u32, vtc: ValueTypeCode) {
		state.addLocals(count, vtc.toAbstractValueType(module));
	}
	def visitOp(opcode: Opcode) {
		bailout(Strings.format1("unsupported opcode: %s", opcode.name));
	}

	def visitProbe() {
		var b = func.orig_bytecode[it.pc];
		last_probe = it.pc;
		if (b != Opcode.LOOP.code && b != Opcode.END.code && b != Opcode.ELSE.code) emitProbe();
	}
	def emitProbe() {
		if (last_probe == 0) return;
		last_probe = 0;
		var c = masm.regAlloc.regConfig;
		// spill everything
		state.emitKill(emitSlotTransfer);
		// compute VSP for potential frame access
		emit_compute_vsp(state.sp);
		masm.emit_write_runtime_vsp(regs.vsp);
		// reload WasmFunction
		masm.emit_mov_r_m(regs.runtime_arg_0, ValueKind.REF, MasmAddr(regs.sp, c.wasm_func_offset));
		// load PC
		masm.emit_mov_r_i(regs.runtime_arg_1, it.pc);
		// call runtime
		masm.emit_call_runtime_Probe_instr();
		emit_reload_regs();
	}
	def visit_UNREACHABLE() {
		emitTrap(TrapReason.UNREACHABLE);
		setUnreachable();
	}
	def visit_NOP() {
		// emit nothing
	}
	def visit_BLOCK(btc: BlockTypeCode) {
		var pr = btc.toAbstractBlockType(module), params = pr.0, results = pr.1;
		state.pushBlock(params, results, masm.newLabel(it.pc));
	}
	def visit_LOOP(btc: BlockTypeCode) {
		var pr = btc.toAbstractBlockType(module), params = pr.0, results = pr.1;
		state.pushLoop(params, results, masm.newLabel(it.pc));
		var ctl_top = state.ctl_stack.peek();
		state.prepareLoop(emitSlotTransfer);
		masm.bindLabel(ctl_top.label);
		emitProbe();
	}
	def visit_IF(btc: BlockTypeCode) {
		var pr = btc.toAbstractBlockType(module), params = pr.0, results = pr.1;
		var sv = state.pop();
		var ctl_top = state.pushIf(params, results, masm.newLabel(it.pc), masm.newLabel(it.pc));
		emitBrIf(sv, MasmBrCond.I32_ZERO, ctl_top.else_label, ctl_top, true);
	}
	def visit_ELSE() {
		var ctl_top = state.ctl_stack.peek();
		state.emitFallthru(emitSlotTransfer);
		masm.emit_br(ctl_top.label);
		masm.bindLabel(ctl_top.else_label);
		state.doElse();
		ctl_top.opcode = Opcode.ELSE.code;
		emitProbe();
	}
	def visit_END() {
		var ctl_top = state.ctl_stack.peek();
		if (ctl_top.opcode == Opcode.LOOP.code) {
			state.ctl_stack.pop();
			state.ctl_stack.peek().reachable = ctl_top.reachable;
		} else if (ctl_top.opcode == Opcode.IF.code) {
			// simulate empty if-true block
			state.emitFallthru(emitSlotTransfer);
			masm.emit_br(ctl_top.label);
			masm.bindLabel(ctl_top.else_label);
			state.doElse();
			ctl_top.opcode = Opcode.ELSE.code;
			state.emitFallthru(emitSlotTransfer);
			masm.bindLabel(ctl_top.label);
			state.resetToMerge(ctl_top);
			state.ctl_stack.pop();
		} else if (ctl_top.opcode == Opcode.BLOCK.code || ctl_top.opcode == Opcode.ELSE.code) {
			state.emitFallthru(emitSlotTransfer);
			masm.bindLabel(ctl_top.label);
			state.resetToMerge(ctl_top);
			state.ctl_stack.pop();
		} else if (ctl_top.opcode == Opcode.RETURN.code) {
			emitProbe();
			state.emitFallthru(emitSlotTransfer);
			masm.bindLabel(ctl_top.label);
			if (ctl_top.merge_count > 1) emitReturn(ctl_top);
			state.ctl_stack.pop();
		}
		emitProbe();
	}
	def visit_BR(depth: u31) {
		var target = state.getControl(depth);
		state.emitTransfer(target, emitSlotTransfer);
		masm.emit_br(target.label);
		setUnreachable();
	}
	def visit_BR_IF(depth: u31) {
		var target = state.getControl(depth);
		var sv = state.pop();
		emitBrIf(sv, MasmBrCond.I32_NONZERO, target.label, target, state.isTransferEmpty(target));
	}
	def visit_BR_ON_NULL(depth: u31) {
		var target = state.getControl(depth);
		var sv = state.pop();
		emitBrIf(sv, MasmBrCond.REF_NULL, target.label, target, state.isTransferEmpty(target));
	}
	def visit_BR_ON_NON_NULL(depth: u31) {
		var target = state.getControl(depth);
		var sv = state.pop();
		emitBrIf(sv, MasmBrCond.REF_NONNULL, target.label, target, state.isTransferEmpty(target));
	}
	def visit_BR_TABLE(depths: Range<u31>) {
		var sv = state.pop();
		emitBrTable(sv, depths);
		setUnreachable();
	}
	def visit_RETURN() {
		var target = state.ctl_stack.elems[0];
		state.emitTransfer(target, emitSlotTransfer);
		masm.emit_br(target.label);
		setUnreachable();
	}
	def visit_CALL(index: u31) {
		var func = module.functions[index];
		var offsets = masm.getOffsets();
		var retpt = masm.newLabel(it.pc), wasmcall_label = masm.newLabel(it.pc);
		state.emitKill(emitSlotTransfer);
		emit_load_instance(regs.instance);
		// XXX: skip loading the target function for direct intra-module calls?
		masm.emit_mov_r_m(regs.func_arg, ValueKind.REF, MasmAddr(regs.instance, offsets.Instance_functions));
		masm.emit_read_v3_array_r_i(regs.func_arg, regs.func_arg, func.func_index, ValueKind.REF);
		emit_compute_vsp(state.sp);

		var tmp = regs.ip; // TODO: more robust register choice for indirect call
		if (func.imp != null) {
			// call to imported function must first check for WasmFunction
			masm.emit_mov_r_m(tmp, ValueKind.I32, MasmAddr(regs.func_arg, 0));
			masm.emit_breq_r_i(tmp, offsets.WasmFunction_typeId, wasmcall_label);
			masm.emit_write_runtime_vsp(regs.vsp);
			masm.emit_mov_r_r(regs.runtime_arg_0, regs.func_arg);
			masm.emit_call_runtime_callHost(regs.func_arg);
			masm.emit_br(retpt);
		}
		masm.bindLabel(wasmcall_label);
		masm.emit_mov_r_m(tmp, ValueKind.REF, MasmAddr(regs.func_arg, offsets.WasmFunction_decl));
		masm.emit_mov_r_m(tmp, ValueKind.REF, MasmAddr(tmp, offsets.FuncDecl_target_code));
		masm.emit_call_r(tmp);
		masm.bindLabel(retpt);
		emit_unwind_check();
		emit_reload_regs();

		state.popArgsAndPushResults(func.sig);
	}
	def visit_CALL_INDIRECT(sig_index: u31, table_index: u31) {
		var sig = SigDecl.!(module.heaptypes[sig_index]);
		var offsets = masm.getOffsets();
		var sv = state.pop();
		var retpt = masm.newLabel(it.pc), wasmcall_label = masm.newLabel(it.pc);
		state.emitKill(emitSlotTransfer);
		ensure_reg(sv, state.sp, regs.func_arg);
		emit_load_instance(regs.instance);

		var tmp1 = regs.stp; // TODO: allocate and release temp regs
		var tmp2 = regs.ip;

		// load table[table_index] from instance
		masm.emit_mov_r_m(tmp1, ValueKind.REF, MasmAddr(regs.instance, offsets.Instance_tables));
		masm.emit_read_v3_array_r_i(tmp1, tmp1, int.!(table_index), ValueKind.REF);
		// bounds check
		masm.emit_mov_r_m(tmp2, ValueKind.REF, MasmAddr(tmp1, offsets.Table_ids));
		masm.emit_bounds_check_v3_array(tmp2, regs.func_arg, masm.newTrapLabel(TrapReason.FUNC_INVALID));
		// signature check
		masm.emit_mov_r_m(tmp2, ValueKind.REF, MasmAddr(tmp1, offsets.Table_ids));
		masm.emit_read_v3_array_r_r(tmp2, tmp2, regs.func_arg, ValueKind.I32);
		masm.emit_breq_r_i(tmp2, -1, masm.newTrapLabel(TrapReason.FUNC_INVALID));
		masm.emit_brne_r_i(tmp2, sig.canon_id, masm.newTrapLabel(TrapReason.FUNC_SIG_MISMATCH));
		// load from table
		masm.emit_mov_r_m(tmp2, ValueKind.REF, MasmAddr(tmp1, offsets.Table_funcs));
		masm.emit_read_v3_array_r_r(regs.func_arg, tmp2, regs.func_arg, ValueKind.REF);

		emit_compute_vsp(state.sp);

		// check for WasmFunction
		masm.emit_mov_r_m(tmp1, ValueKind.I32, MasmAddr(regs.func_arg, 0));
		masm.emit_breq_r_i(tmp1, offsets.WasmFunction_typeId, wasmcall_label);
		masm.emit_write_runtime_vsp(regs.vsp);
		masm.emit_mov_r_r(regs.runtime_arg_0, regs.func_arg);
		masm.emit_call_runtime_callHost(regs.func_arg);
		masm.emit_br(retpt);

		masm.bindLabel(wasmcall_label);
		masm.emit_mov_r_m(tmp1, ValueKind.REF, MasmAddr(regs.func_arg, offsets.WasmFunction_decl));
		masm.emit_mov_r_m(tmp1, ValueKind.REF, MasmAddr(tmp1, offsets.FuncDecl_target_code));
		masm.emit_call_r(tmp1);
		// merge point for both returns
		masm.bindLabel(retpt);
		emit_unwind_check();
		emit_reload_regs();

		state.popArgsAndPushResults(sig);
		freeVal(sv);
	}
	def visit_CALL_REF(index: u31) {
		var sig = SigDecl.!(module.heaptypes[index]);
		var offsets = masm.getOffsets();
		var regs = masm.regAlloc.regConfig.regs;
		var sv = state.pop();
		if (sv.isConst() && sv.const == 0) {
			emitTrap(TrapReason.NULL_DEREF);
			setUnreachable();
			return;
		}
		ensure_reg(sv, state.sp, regs.func_arg);
		var retpt = masm.newLabel(it.pc), wasmcall_label = masm.newLabel(it.pc);
		state.emitKill(emitSlotTransfer);

		emit_compute_vsp(state.sp);
		// check for null
		masm.emit_breq_r_l(regs.func_arg, 0, masm.newTrapLabel(TrapReason.NULL_DEREF));

		var tmp = regs.ip; // TODO: allocate and release tmp regs
		masm.emit_mov_r_m(tmp, ValueKind.I32, MasmAddr(regs.func_arg, 0));
		masm.emit_breq_r_i(tmp, offsets.WasmFunction_typeId, wasmcall_label);
		// not a WasmFunction
		masm.emit_write_runtime_vsp(regs.vsp);
		masm.emit_mov_r_r(regs.runtime_arg_0, regs.func_arg);
		masm.emit_call_runtime_callHost(regs.func_arg);
		masm.emit_br(retpt);

		// WasmFunction
		masm.bindLabel(wasmcall_label);
		masm.emit_mov_r_m(tmp, ValueKind.REF, MasmAddr(regs.func_arg, offsets.WasmFunction_decl));
		masm.emit_mov_r_m(tmp, ValueKind.REF, MasmAddr(tmp, offsets.FuncDecl_target_code));
		masm.emit_call_r(tmp);

		masm.bindLabel(retpt);
		emit_unwind_check();
		emit_reload_regs();

		state.popArgsAndPushResults(sig);
		freeVal(sv);
	}
	def visit_DROP() {
		var sv = state.pop();
		freeVal(sv);
	}
	def visit_SELECT() {
		var sv = state.pop();
		var fv = state.pop();
		var tv = state.pop();
		emitSelect1(sv, fv, tv);
		freeVal(sv);
	}
	def visit_LOCAL_GET(index: u31) {
		var lv = state.get(index);
		if (lv.isConst()) {
			if (lv.inReg()) {
				state.push(lv.kindFlags(IS_CONST | IN_REG), lv.reg, lv.const); // steal reg
				state.setNoReg(index);
			} else {
				state.push(lv.kindFlags(IS_CONST), NO_REG, lv.const);
			}
		} else if (lv.inReg()) {
			if (!lv.isStored()) {
				masm.emit_mov_s_r(index, lv.reg, lv.kind());
				state.setStored(index);
			}
			state.setNoReg(index); // steal reg
			state.push(lv.kindFlags(IN_REG), lv.reg, 0);
		} else {
			var reg = allocReg(lv.kind());
			emit_read_slot_r(index, reg);
			state.push(lv.kindFlags(IN_REG), reg.reg, 0);
		}
	}
	def visit_LOCAL_SET(index: u31) {
		var lv = state.get(index);
		var sv = state.pop();
		if (sv.isConst() || sv.inReg()) {
			var flags = (lv.flags & (KIND_MASK | TAG_STORED)) | (sv.flags & (IN_REG | IS_CONST));
			state.set(index, flags, sv.reg, sv.const);
			freeVal(lv);
		} else {
			var reg = allocReg(lv.kind());
			emit_read_slot_r(state.sp, reg);
			var flags = (lv.flags & (KIND_MASK | TAG_STORED)) | IN_REG;
			state.set(index, flags, reg.reg, 0);
		}
	}
	def visit_LOCAL_TEE(index: u31) {
		var lv = state.get(index);
		var sv = state.peek();
		if (sv.isConst()) {
			var flags = lv.kindFlagsAndTag(IS_CONST);
			state.set(index, flags, NO_REG, sv.const);
		} else if (sv.inReg()) {
			masm.emit_mov_s_r(index, sv.reg, sv.kind());
			var flags = lv.kindFlagsAndTag(IS_STORED);
			state.set(index, flags, NO_REG, 0);
		} else {
			var tos = state.sp - 1;
			var reg = allocReg(lv.kind());
			emit_read_slot_r(tos, reg);
			emit_write_slot_r(index, reg);
			var flags = lv.kindFlagsAndTag(IS_STORED);
			state.set(index, flags, NO_REG, 0);
			state.overwrite(lv.kindFlags(IN_REG), reg.reg, 0);
		}
	}
	def visit_GLOBAL_GET(index: u31) {
		var global = module.globals[index];
		if (!global.mutable && global.imp == null && InitExpr.I32.?(global.init)) {
			state.push(KIND_I32 | IS_CONST, NO_REG, InitExpr.I32.!(global.init).val);
		} else {
			emit_call_runtime_op1n(Opcode.GLOBAL_GET, index, 0, [global.valtype], false);
		}
	}
	def visit_GLOBAL_SET(index: u31) {
		emit_call_runtime_op1n(Opcode.GLOBAL_SET, index, 1, ValueTypes.NONE, false);
	}
	def visit_TABLE_GET(index: u31) {
		var table = module.tables[index];
		emit_call_runtime_op1n(Opcode.TABLE_GET, index, 1, [table.elemtype], true);
	}
	def visit_TABLE_SET(index: u31) {
		var table = module.tables[index];
		emit_call_runtime_op1n(Opcode.TABLE_SET, index, 2, ValueTypes.NONE, true);
	}

	def visit_I32_LOAD(imm: MemArg) { emitLoad(imm, ValueKind.I32, masm.emit_load_r_r_r_i); }
	def visit_I64_LOAD(imm: MemArg) { emitLoad(imm, ValueKind.I64, masm.emit_load_r_r_r_i); }
	def visit_F32_LOAD(imm: MemArg) { emitLoad(imm, ValueKind.F32, masm.emit_load_r_r_r_i); }
	def visit_F64_LOAD(imm: MemArg) { emitLoad(imm, ValueKind.F64, masm.emit_load_r_r_r_i); }
	def visit_I32_LOAD8_S(imm: MemArg) { emitLoad(imm, ValueKind.I32, masm.emit_loadbsx_r_r_r_i); }
	def visit_I32_LOAD8_U(imm: MemArg) { emitLoad(imm, ValueKind.I32, masm.emit_loadbzx_r_r_r_i); }
	def visit_I32_LOAD16_S(imm: MemArg) { emitLoad(imm, ValueKind.I32, masm.emit_loadwsx_r_r_r_i); }
	def visit_I32_LOAD16_U(imm: MemArg) { emitLoad(imm, ValueKind.I32, masm.emit_loadwzx_r_r_r_i); }
	def visit_I64_LOAD8_S(imm: MemArg) { emitLoad(imm, ValueKind.I64, masm.emit_loadbsx_r_r_r_i); }
	def visit_I64_LOAD8_U(imm: MemArg) { emitLoad(imm, ValueKind.I64, masm.emit_loadbzx_r_r_r_i); }
	def visit_I64_LOAD16_S(imm: MemArg) { emitLoad(imm, ValueKind.I64, masm.emit_loadwsx_r_r_r_i); }
	def visit_I64_LOAD16_U(imm: MemArg) { emitLoad(imm, ValueKind.I64, masm.emit_loadwzx_r_r_r_i); }
	def visit_I64_LOAD32_S(imm: MemArg) { emitLoad(imm, ValueKind.I64, masm.emit_loaddsx_r_r_r_i); }
	def visit_I64_LOAD32_U(imm: MemArg) { emitLoad(imm, ValueKind.I64, masm.emit_loaddzx_r_r_r_i); }
	def visit_I32_STORE(imm: MemArg) { emitStore(imm, ValueKind.I32, masm.emit_store_r_r_r_i); }
	def visit_I64_STORE(imm: MemArg) { emitStore(imm, ValueKind.I64, masm.emit_store_r_r_r_i); }
	def visit_F32_STORE(imm: MemArg) { emitStore(imm, ValueKind.F32, masm.emit_store_r_r_r_i); }
	def visit_F64_STORE(imm: MemArg) { emitStore(imm, ValueKind.F64, masm.emit_store_r_r_r_i); }
	def visit_I32_STORE8(imm: MemArg) { emitStore(imm, ValueKind.I32, masm.emit_storeb_r_r_r_i); }
	def visit_I32_STORE16(imm: MemArg) { emitStore(imm, ValueKind.I32, masm.emit_storew_r_r_r_i); }
	def visit_I64_STORE8(imm: MemArg) { emitStore(imm, ValueKind.I64, masm.emit_storeb_r_r_r_i); }
	def visit_I64_STORE16(imm: MemArg) { emitStore(imm, ValueKind.I64, masm.emit_storew_r_r_r_i); }
	def visit_I64_STORE32(imm: MemArg) { emitStore(imm, ValueKind.I32, masm.emit_store_r_r_r_i); }

	def visit_MEMORY_SIZE(memory_index: u31) {
		var offsets = masm.getOffsets();
		var reg = allocReg(ValueKind.REF).reg;
		var r1 = allocReg(ValueKind.I64).reg;
		var r2 = allocReg(ValueKind.I64).reg;
		emit_load_instance(reg);
		masm.emit_mov_r_m(reg, ValueKind.REF, MasmAddr(reg, offsets.Instance_memories));
		masm.emit_read_v3_array_r_i(reg, reg, int.!(memory_index), ValueKind.REF);
		masm.emit_mov_r_m(r2, ValueKind.REF, MasmAddr(reg, offsets.X86_64Memory_start));
		masm.emit_mov_r_m(r1, ValueKind.REF, MasmAddr(reg, offsets.X86_64Memory_limit));
		masm.emit_subw_r_r(r1, r2);
		masm.emit_shrw_r_i(r1, 16);
		freeReg(r2);
		freeReg(reg);
		state.push(KIND_I32 | IN_REG, r1, 0);
	}
	def visit_MEMORY_GROW(memory_index: u31) {
		emit_call_runtime_op1(Opcode.MEMORY_GROW, memory_index, false);
	}

	def visit_I32_CONST(val: i32) {
		state.push(KIND_I32 | IS_CONST, NO_REG, val);
	}
	def visit_I64_CONST(val: i64) {
		if (i32.view(val) == val) {
			state.push(KIND_I64 | IS_CONST, NO_REG, i32.view(val));
		} else {
			var tos = state.sp;
			var addr = masm.slotAddr(tos);
			masm.emit_mov_m_i(addr, int.view(val));
			masm.emit_mov_m_i(addr.plus(4), int.view(val >> 32));
			state.push(KIND_I64 | IS_STORED, NO_REG, 0);
		}
	}
	def visit_F32_CONST(val: u32) {
		if (val == 0 && config_TrackFloatZeroConst) {
			state.push(KIND_F32 | IS_CONST, NO_REG, 0);
		} else {
			var tos = state.sp;
			masm.emit_mov_m_i(masm.slotAddr(tos), int.view(val));
			state.push(KIND_F32 | IS_STORED, NO_REG, 0);
		}
	}
	def visit_F64_CONST(val: u64) {
		if (val == 0 && config_TrackFloatZeroConst) {
			state.push(KIND_F64 | IS_CONST, NO_REG, 0);
		} else {
			var tos = state.sp;
			var addr = masm.slotAddr(tos);
			masm.emit_mov_m_i(addr, int.view(val));
			masm.emit_mov_m_i(addr.plus(4), int.view(val >> 32));
			state.push(KIND_F64 | IS_STORED, NO_REG, 0);
		}
	}

	def visit_REF_NULL(ht_index: u31) {
		state.push(KIND_REF | IS_CONST, NO_REG, 0);
	}
	def visit_REF_FUNC(func_index: u31) {
		var offsets = masm.getOffsets();
		var reg = allocReg(ValueKind.REF).reg;
		emit_load_instance(reg);
		// XXX: skip loading the target function for direct intra-module calls?
		masm.emit_mov_r_m(reg, ValueKind.REF, MasmAddr(reg, offsets.Instance_functions));
		masm.emit_read_v3_array_r_i(reg, reg, int.!(func_index), ValueKind.REF);
		state.push(KIND_REF | IN_REG, reg, 0);
	}
	def visit_REF_AS_NON_NULL() {
		var sv = state.peek();
		if (sv.isConst()) {
			if (sv.const == 0) {
				masm.emit_br(masm.newTrapLabel(TrapReason.NULL_DEREF)); // statically null
			} else {
				// nop
			}
		} else if (sv.inReg()) {
			masm.emit_br_r(sv.reg, MasmBrCond.REF_NULL, masm.newTrapLabel(TrapReason.NULL_DEREF));
		} else {
			var reg = allocReg(ValueKind.REF);
			emit_read_slot_r(state.sp - 1, reg);
			masm.emit_br_r(reg.reg, MasmBrCond.REF_NULL, masm.newTrapLabel(TrapReason.NULL_DEREF));
			state.overwrite(sv.kindFlagsAndTag(IN_REG | (sv.flags & IS_STORED)), reg.reg, 0);
		}
	}
	def visit_EXTERN_INTERNALIZE() { } // nop
	def visit_EXTERN_EXTERNALIZE() { } // nop

	def visit_MEMORY_INIT(dindex: u31, mindex: u31) {
		emit_call_runtime_op2(Opcode.MEMORY_INIT, dindex, mindex, true);
	}
	def visit_DATA_DROP(dindex: u31) {
		var offsets = masm.getOffsets();
		var tmp = allocReg(ValueKind.REF).reg;
		emit_load_instance(tmp);
		masm.emit_mov_r_m(tmp, ValueKind.REF, MasmAddr(tmp, offsets.Instance_dropped_data));
		var addr = MasmAddr(tmp, offsets.Array_contents + dindex);
		masm.emit_mov_m_i(addr, 1);
		freeReg(tmp);
	}
	def visit_MEMORY_COPY(mindex1: u31, mindex2: u31) {
		emit_call_runtime_op2(Opcode.MEMORY_COPY, mindex1, mindex2, true);
	}
	def visit_MEMORY_FILL(mindex: u31) {
		emit_call_runtime_op1(Opcode.MEMORY_FILL, mindex, true);
	}
	def visit_TABLE_INIT(eindex: u31, tindex: u31) {
		emit_call_runtime_op2(Opcode.TABLE_INIT, eindex, tindex, true);
	}
	def visit_ELEM_DROP(dindex: u31) {
		var offsets = masm.getOffsets();
		var tmp = allocReg(ValueKind.REF).reg;
		emit_load_instance(tmp);
		masm.emit_mov_r_m(tmp, ValueKind.REF, MasmAddr(tmp, offsets.Instance_dropped_elems));
		var addr = MasmAddr(tmp, offsets.Array_contents + dindex);
		masm.emit_mov_m_i(addr, 1);
		freeReg(tmp);
	}
	def visit_TABLE_COPY(tindex1: u31, tindex2: u31) {
		emit_call_runtime_op2(Opcode.TABLE_COPY, tindex1, tindex2, true);
	}
	def visit_TABLE_GROW(index: u31) {
		emit_call_runtime_op1n(Opcode.TABLE_GROW, index, 2, [ValueType.I32], false);
	}
	def visit_TABLE_SIZE(table_index: u31) {
		var offsets = masm.getOffsets();
		var tmp = allocReg(ValueKind.REF).reg;
		var r1 = allocReg(ValueKind.I32).reg;
		emit_load_instance(tmp);
		masm.emit_mov_r_m(tmp, ValueKind.REF, MasmAddr(tmp, offsets.Instance_tables));
		masm.emit_read_v3_array_r_i(tmp, tmp, int.!(table_index), ValueKind.REF);
		masm.emit_mov_r_m(tmp, ValueKind.REF, MasmAddr(tmp, offsets.Table_elems));
		masm.emit_read_v3_array_length_r_r(r1, tmp);
		freeReg(tmp);
		state.push(KIND_I32 | IN_REG, r1, 0);
	}
	def visit_TABLE_FILL(index: u31) {
		emit_call_runtime_op1n(Opcode.TABLE_FILL, index, 3, ValueTypes.NONE, true);
	}

	def emit_call_runtime_op1(op: Opcode, arg1: u31, canTrap: bool) {
		emit_call_runtime_op1n(op, arg1, op.sig.params.length, op.sig.results, canTrap);
	}
	def emit_call_runtime_op2(op: Opcode, arg1: u31, arg2: u31, canTrap: bool) {
		emit_call_runtime_op2n(op, arg1, arg2, op.sig.params.length, op.sig.results, canTrap);
	}
	def emit_call_runtime_op1n(op: Opcode, arg1: u31, args: int, results: Array<ValueType>, canTrap: bool) {
		state.emitKill(emitSlotTransfer);
		emit_compute_vsp(state.sp);
		masm.emit_write_runtime_vsp(regs.vsp);
		emit_load_instance(regs.runtime_arg_0);
		masm.emit_mov_r_i(regs.runtime_arg_1, arg1);
		masm.emit_call_runtime_op(op);
		if (canTrap) emit_unwind_check();
		for (i < args) state.pop();
		for (t in results) state.push(typeToKindFlags(t) | TAG_STORED | IS_STORED, NO_REG, 0);
		emit_reload_regs();
	}
	def emit_call_runtime_op2n(op: Opcode, arg1: u31, arg2: u31, args: int, results: Array<ValueType>, canTrap: bool) {
		state.emitKill(emitSlotTransfer);
		emit_compute_vsp(state.sp);
		masm.emit_write_runtime_vsp(regs.vsp);
		emit_load_instance(regs.runtime_arg_0);
		masm.emit_mov_r_i(regs.runtime_arg_1, arg1);
		masm.emit_mov_r_i(regs.runtime_arg_2, arg2);
		masm.emit_call_runtime_op(op);
		if (canTrap) emit_unwind_check();
		for (i < args) state.pop();
		for (t in results) state.push(typeToKindFlags(t) | TAG_STORED | IS_STORED, NO_REG, 0);
		emit_reload_regs();
	}

	def emitSelect1(sv: SpcAbstractVal, fv: SpcAbstractVal, tv: SpcAbstractVal) {
		var tagStored = tv.flags & TAG_STORED;
		var label = masm.newLabel(it.pc);
		if (tv.isConst() && fv.isConst() && tv.const == fv.const) {
			// select K K v() K
			freeVal(tv);
			freeVal(fv);
			state.push(tv.kindFlags(IS_CONST), NO_REG, tv.const);
			return;
		}
		if (sv.isConst()) {
			// select v v K => v
			if (sv.const != 0) {
				freeVal(fv);
				state.pushV(tv);
			} else {
				freeVal(tv);
				if (fv.isConst() || fv.inReg()) state.push(fv.flags & ~IS_STORED, fv.reg, fv.const);
				else {
					var kind = fv.kind();
					var reg = allocReg(kind);
					emit_read_slot_r(state.sp + 1, reg);
					state.push(fv.kindFlags(IN_REG | tagStored), reg.reg, 0);
				}
			}
			return;
		}
		if (tv.inReg()) {
			// reuse register for true value
			var cond = MasmBrCond.I32_NONZERO;
			if (sv.inReg()) masm.emit_br_r(sv.reg, cond, label);
			else masm.emit_br_m(masm.slotAddr(state.sp + 2), cond, label);

			if (fv.isConst()) masm.emit_mov_r_k(tv.reg, tv.kind(), fv.const);
			else if (fv.inReg()) masm.emit_mov_r_r(tv.reg, fv.reg);
			else masm.emit_mov_r_s(tv.reg, tv.kind(), state.sp + 1);
			masm.bindLabel(label);
			state.push(tv.kindFlags(IN_REG | tagStored), tv.reg, 0);
			freeVal(fv);
		} else {
			// load const true value into slot first
			if (!tv.isStored()) masm.emit_mov_s_k(state.sp, tv.const, tv.kind());

			// XXX: reuse the false register and flip branch if possible
			var cond = MasmBrCond.I32_NONZERO;
			if (sv.inReg()) masm.emit_br_r(sv.reg, cond, label);
			else masm.emit_br_m(masm.slotAddr(state.sp + 2), cond, label);

			if (fv.isConst()) masm.emit_mov_s_k(state.sp, fv.const, tv.kind());
			else if (fv.inReg()) masm.emit_mov_s_r(state.sp, fv.reg, tv.kind());
			else masm.emit_mov_s_s(state.sp, state.sp + 1, tv.kind());
			masm.bindLabel(label);
			state.push(tv.kindFlags(IS_STORED | tagStored), NO_REG, 0);
			freeVal(fv);
		}
	}
	def emitBrIf(sv: SpcAbstractVal, cond: MasmBrCond, label: MasmLabel, target: SpcControl, emptyTransfer: bool) {
		if (sv.isConst()) {
			var taken = (sv.const == 0) == cond.zero;
			if (taken) {
				if (!emptyTransfer) state.emitTransfer(target, emitSlotTransfer);
				masm.emit_br(target.label);
			}
		} else if (sv.inReg()) {
			if (emptyTransfer) {
				masm.emit_br_r(sv.reg, cond, label);
			} else {
				var skip = masm.newLabel(it.pc);
				masm.emit_br_r(sv.reg, masm.negate(cond), skip);
				state.emitTransfer(target, emitSlotTransfer);
				masm.emit_br(label);
				masm.bindLabel(skip);
			}
		} else {
			if (emptyTransfer) {
				masm.emit_br_m(masm.slotAddr(state.sp), cond, label);
			} else {
				var skip = masm.newLabel(it.pc);
				masm.emit_br_m(masm.slotAddr(state.sp), masm.negate(cond), skip);
				state.emitTransfer(target, emitSlotTransfer);
				masm.emit_br(label);
				masm.bindLabel(skip);
			}
		}
		freeVal(sv);
	}
	def emitBrTable(sv: SpcAbstractVal, depths: Range<u31>) {
		if (sv.isConst()) {
			// constant-fold br_table into a br
			var key = sv.const;
			if (u32.view(key) >= depths.length) key = depths.length - 1;
			var target = state.getControl(depths[key]);
			state.emitTransfer(target, emitSlotTransfer);
			masm.emit_br(target.label);
			return;
		}
		var labels = Array<MasmLabel>.new(state.ctl_stack.top);
		var targets = Array<MasmLabel>.new(depths.length);
		for (i < targets.length) { // create labels for all targets involved in this br_table
			var depth = depths[i];
			var l = labels[depth];
			if (l == null) l = labels[depth] = masm.newLabel(it.pc);
			targets[i] = l;
		}
		var reg = ensure_reg(sv, state.sp, NO_REG);
		masm.emit_br_table_r(reg, targets);
		freeReg(reg);

		for (depth < labels.length) {
			var l = labels[depth];
			if (l == null) continue;
			masm.bindLabel(l);
			var target = state.getControl(u32.view(depth));
			state.emitTransfer(target, emitSlotTransfer);
			masm.emit_br(target.label);
		}
	}
	def emitReturn(ctl: SpcControl) {
		var results = sig.results;
		if (masm.valuerep.tagged) {
			// update mismatched value tags
			var params = sig.params;
			for (i < results.length) {
				var rtag = toTag(results[i]);
				if (i < params.length && rtag == toTag(params[i])) continue; // tag already correct
				masm.emit_mov_m_i(masm.tagAddr(u32.view(i)), rtag.code);
			}
		}
		// Compute VSP = VFP + sig.results.length
		var c = masm.regAlloc.regConfig;
		masm.emit_mov_r_r(regs.vsp, regs.vfp); // XXX: use 3-addr adjustment of VSP
		if (results.length > 0)	masm.emit_addw_r_i(regs.vsp, results.length * masm.valuerep.slot_size);
		// Return to caller
		masm.emit_mov_r_i(regs.ret_Abrupt, 0);
		// Deallocate stack frame
		if (unwind_label != null) masm.bindLabel(unwind_label);
		masm.emit_addw_r_i(regs.sp, c.spcFrameSize);
		masm.emit_ret();
	}
	def emitTrap(reason: TrapReason) {
		var label = masm.newTrapLabel(reason);
		masm.emit_br(label);
	}
	def emitTrapReturn(label: MasmLabel, reason: TrapReason) {
		if (label != null) masm.bindLabel(label);
		var c = masm.regAlloc.regConfig;
		masm.emit_mov_r_trap(regs.ret_Abrupt, reason);
		masm.emit_addw_r_i(regs.sp, c.spcFrameSize);
		masm.emit_ret();
	}
	def emitSlotTransfer(to: (u32, SpcAbstractVal), from: (u32, SpcAbstractVal)) {
		if (Trace.compiler) {
			OUT.put1("    emitSlotTransfer slot=%d ", to.0);
			traceAbstractVal(to.1);
			OUT.put1(" <- slot=%d ", from.0);
			traceAbstractVal(from.1);
			OUT.outln();
		}
		var tv = to.1, fv = from.1;
		if (masm.valuerep.tagged && tv.tagStored()) {
			if (from.0 != to.0 || !fv.tagStored()) {
				// store the tag into to-slot
				masm.emit_mov_m_i(masm.tagAddr(to.0), fv.kind().code);
			}
		}
		if (tv.isStored()) {
			// store the value into slot
			if (from.0 != to.0 || !fv.isStored()) {
				if (fv.isConst()) {
					masm.emit_mov_s_k(to.0, fv.const, fv.kind());
				} else if (fv.inReg()) {
					masm.emit_mov_s_r(to.0, fv.reg, fv.kind());
				} else {
					masm.emit_mov_s_s(to.0, from.0, tv.kind());
				}
			}
		} else if (tv.inReg()) {
			// load or move the value into appropriate register
			if (fv.isConst()) {
				masm.emit_mov_r_i(tv.reg, fv.const);
			} else if (fv.inReg()) {
				if (tv.reg != fv.reg) {
					// XXX: perform reg-reg move instead of storing to slot
					masm.emit_mov_s_r(to.0, fv.reg, fv.kind());
					masm.emit_mov_r_s(tv.reg, fv.kind(), to.0);
				}
			} else {
				masm.emit_mov_r_s(tv.reg, tv.kind(), from.0);
			}
		}
	}
	def unsupported() {
		success = false; // XXX: add opcode
	}
	def bailout(msg: string) {
		success = false;
		if (Trace.compiler) Trace.OUT.put1("------------ bailout: %s", msg).outln();
		var cp = it.immptr();
		err.rel(cp, it.pc).set(msg);
	}

	// Fold an unary operation if a constant is on the top of the stack.
	def tryFold_i_i(f: i32 -> i32) -> bool {
		var sv = state.peek();
		if (sv.isConst()) {
			var r = f(sv.const);
			if (r != sv.const) {
				freeVal(sv);
				state.overwrite(KIND_I32 | IS_CONST, NO_REG, r);
			}
			return true;
		}
		return false;
	}
	def tryFold_x_y<X, Y>(kind: ValueKind, f: X -> Y, toX: i32 -> X, toY: i32 -> Y, fromY: Y -> i32) -> bool {
		var a = state.peek();
		if (a.isConst()) {
			var rY = f(toX(a.const));
			var r = fromY(rY);
			var cY = toY(r);
			if (cY != rY) return false;
			freeVal(a);
			state.overwrite(SpcConsts.kindToFlags(kind) | IS_CONST, NO_REG, r);
			return true;
		}
		return false;
	}
	def tryFold_u_u(f: u32 -> u32) -> bool { return tryFold_x_y(ValueKind.I32, f, u32.view<i32>, u32.view<i32>, i32.view<u32>); }
	def tryFold_i_l(f: i32 -> i64) -> bool { return tryFold_x_y(ValueKind.I64, f, i32.view<i32>, i64.view<i32>, i32.view<i64>); }
	def tryFold_u_l(f: u32 -> i64) -> bool { return tryFold_x_y(ValueKind.I64, f, u32.view<i32>, i64.view<i32>, i32.view<i64>); }
	def tryFold_q_q(f: u64 -> u64) -> bool { return tryFold_x_y(ValueKind.I64, f, u64.view<i32>, u64.view<i32>, i32.view<u64>); }
	def tryFold_l_i(f: i64 -> i32) -> bool { return tryFold_x_y(ValueKind.I32, f, i64.view<i32>, i32.view<i32>, i32.view<i32>); }
	def tryFold_l_l(f: i64 -> i64) -> bool { return tryFold_x_y(ValueKind.I64, f, i64.view<i32>, i64.view<i32>, i32.view<i64>); }

	// Utilities to try to constant-fold using the given evaluation function {f}. Since all SPC constants
	// are represented by the V3 type {i32}, this is the fast path.
	def tryFold_ii_i(f: (i32, i32) -> i32) -> bool {
		var sv = state.peek2(), a = sv.0, b = sv.1;
		if (a.isConst() && b.isConst()) {
			var r = f(a.const, b.const);
			freeVal(a);
			freeVal(b);
			state.pop();
			state.overwrite(KIND_I32 | IS_CONST, NO_REG, r);
			return true;
		}
		return false;
	}
	// For evaluation functions that are not of type {i32}, adapt them polymorphically.
	def tryFold_xx_y<X, Y>(kind: ValueKind, f: (X, X) -> Y, toX: i32 -> X, toY: i32 -> Y, fromY: Y -> i32) -> bool {
		var sv = state.peek2(), a = sv.0, b = sv.1;
		if (a.isConst() && b.isConst()) {
			var rY = f(toX(a.const), toX(b.const));
			var r = fromY(rY);
			var cY = toY(r);
			if (cY != rY) return false;
			freeVal(a);
			freeVal(b);
			state.pop();
			state.overwrite(SpcConsts.kindToFlags(kind) | IS_CONST, NO_REG, r);
			return true;
		}
		return false;
	}
	// All the polymorphic variants of folding.
	def tryFold_uu_u(f: (u32, u32) -> u32) -> bool   { return tryFold_xx_y(ValueKind.I32, f, u32.view<i32>, u32.view<i32>, i32.view<u32>); }
	def tryFold_ii_z(f: (i32, i32) -> bool) -> bool  { return tryFold_xx_y(ValueKind.I32, f, i32.view<i32>, isNotZero, trueToOne); }
	def tryFold_uu_z(f: (u32, u32) -> bool) -> bool  { return tryFold_xx_y(ValueKind.I32, f, u32.view<i32>, isNotZero, trueToOne); }
	def tryFold_ll_l(f: (i64, i64) -> i64) -> bool   { return tryFold_xx_y(ValueKind.I64, f, i64.view<i32>, i64.view<i32>, i32.view<i64>); }
	def tryFold_qq_q(f: (u64, u64) -> u64) -> bool   { return tryFold_xx_y(ValueKind.I64, f, u64.view<i32>, u64.view<i32>, i32.view<u64>); }
	def tryFold_ll_z(f: (i64, i64) -> bool) -> bool  { return tryFold_xx_y(ValueKind.I32, f, i64.view<i32>, isNotZero, trueToOne); }
	def tryFold_qq_z(f: (u64, u64) -> bool) -> bool  { return tryFold_xx_y(ValueKind.I32, f, u64.view<i32>, isNotZero, trueToOne); }

	//====================================================================
	// codegen operations
	//====================================================================
	def emit_read_slot_r(slot: u32, reg: SpcReg) {
		masm.emit_mov_r_s(reg.reg, reg.kind, slot);
	}
	def emit_write_slot_r(slot: u32, reg: SpcReg) {
		masm.emit_mov_s_r(slot, reg.reg, reg.kind);
	}
	def emit_unwind_check() {
		if (unwind_label == null) unwind_label = masm.newLabel(func.cur_bytecode.length);
		masm.emit_brne_r_i(regs.ret_Abrupt, 0, unwind_label);
	}
	def emit_compute_vsp(slots: u32) {
		masm.emit_mov_r_r(regs.vsp, regs.vfp); // XXX: use 3-addr adjustment of VSP (i.e. lea)
		if (slots > 0) masm.emit_addw_r_i(regs.vsp, int.view(slots) * masm.valuerep.slot_size);
	}
	def emit_reload_regs() {
		// XXX: recompute VFP from VSP - #slots?
		masm.emit_mov_r_m(regs.vfp, ValueKind.REF, MasmAddr(regs.sp, masm.regAlloc.regConfig.vfp_offset));
		if (module.memories.length > 0) {
			masm.emit_mov_r_m(regs.mem0, ValueKind.REF, MasmAddr(regs.sp, masm.regAlloc.regConfig.mem_offset));
		}
	}
	def emit_load_instance(reg: Reg) {
		masm.emit_mov_r_m(reg, ValueKind.REF, MasmAddr(regs.sp, masm.regAlloc.regConfig.instance_offset));
	}
	def ensure_reg(sv: SpcAbstractVal, slot: u32, reg: Reg) -> Reg {
		if (!sv.inReg()) {
			if (reg == NO_REG) reg = allocReg(sv.kind()).reg;
			if (sv.isConst()) masm.emit_mov_r_i(reg, sv.const);
			else masm.emit_mov_r_s(reg, sv.kind(), slot);
			return reg;
		}
		if (reg == NO_REG) return sv.reg;
		masm.emit_mov_r_r(reg, sv.reg);
		return reg;
	}
	def emitLoad(imm: MemArg, kind: ValueKind, meth: (Reg, Reg, Reg, u32, ValueKind) -> ())  {
		if (imm.memory_index != 0) bailout("unsupported multi-memory operation");
		var iv = state.pop();
		var index_reg: Reg;
		var offset = imm.offset;
		if (iv.isConst()) {
			var sum = u64.view(offset) + u32.view(iv.const); // fold offset calculation
			if (sum > u32.max) {
				masm.emit_br(masm.newTrapLabel(TrapReason.MEM_OUT_OF_BOUNDS)); // statically OOB
				setUnreachable();
				return;
			}
			offset = u32.view(sum);
		} else {
			index_reg = ensure_reg(iv, state.sp, NO_REG);
		}
		var dest = index_reg;
		if (kind != ValueKind.I32 || dest == NO_REG) dest = allocReg(kind).reg;
		meth(dest, regs.mem0, index_reg, offset, kind);
		if (dest != index_reg) freeReg(index_reg);
		var nflags = IN_REG | SpcConsts.kindToFlags(kind);
		if (kind == ValueKind.I32) nflags |= (iv.flags & TAG_STORED); // tag may already be stored for index
		state.push(nflags, dest, 0);
	}
	def emitStore(imm: MemArg, kind: ValueKind, meth: (Reg, Reg, Reg, u32, ValueKind) -> ()) {
		if (imm.memory_index != 0) bailout("unsupported multi-memory operation");
		var offset = imm.offset;
		var sv = state.pop();
		var val_reg = ensure_reg(sv, state.sp, NO_REG); // XXX: support store immediate
		var iv = state.pop();
		var index_reg: Reg;
		if (iv.isConst()) {
			var sum = u64.view(offset) + u32.view(iv.const); // fold offset calculation
			if (sum > u32.max) {
				masm.emit_br(masm.newTrapLabel(TrapReason.MEM_OUT_OF_BOUNDS)); // statically OOB
				setUnreachable();
				return;
			}
			offset = u32.view(sum);
		} else {
			index_reg = ensure_reg(iv, state.sp, NO_REG);
		}
		meth(val_reg, regs.mem0, index_reg, offset, kind);
		freeReg(val_reg);
		freeReg(index_reg);
	}

	//====================================================================
	// register allocation operations
	//====================================================================
	def freeReg(reg: Reg) {
		if (reg.index > 0) masm.regAlloc.free(reg);
	}
	def freeVal(sv: SpcAbstractVal) {
		if (sv.inReg()) masm.regAlloc.free(sv.reg);
	}
	def allocReg(kind: ValueKind) -> SpcReg {
		// TODO: handle running out of registers
		var reg = masm.regAlloc.alloc(kind, 2);
		if (reg == NO_REG) bailout("out of registers");
		return SpcReg(reg, kind);
	}

	//====================================================================
	// abstract stack operations
	//====================================================================
	def labelArgs(ctl: SpcControl) -> Array<ValueType> {
		if (ctl.opcode == Opcode.LOOP.code) return ctl.params;
		else return ctl.results;
	}
	// Pop the top of the stack into a register of the appropriate kind.
	def popReg() -> SpcAbstractVal {
		var sv = state.pop();
		if (sv.inReg()) return sv;
		var kind = sv.kind();
		var reg = allocReg(kind).reg;
		if (sv.isConst()) masm.emit_mov_r_k(reg, kind, sv.const);
		else masm.emit_mov_r_s(reg, kind, state.sp);
		return SpcAbstractVal(sv.flags | IN_REG, reg, sv.const);
	}
	// Pop the top of the stack into {reg}, spilling any value(s) in {reg} first.
	def popFixedReg(reg: Reg) -> SpcAbstractVal {
		var sv = state.pop();
		if (sv.inReg()) {
			if (sv.reg == reg) return sv;
			reassignReg(reg, int.!(state.sp));
			masm.emit_mov_r_r(reg, sv.reg);
			freeReg(sv.reg);
			return SpcAbstractVal(sv.flags, reg, sv.const);
		}
		var kind = sv.kind();
		reassignReg(reg, int.!(state.sp));
		if (sv.isConst()) masm.emit_mov_r_k(reg, kind, sv.const);
		else masm.emit_mov_r_s(reg, kind, state.sp);
		return SpcAbstractVal(sv.flags | IN_REG, reg, sv.const);
	}
	def reassignReg(reg: Reg, slot: int) {
		spillReg(reg);
		freeReg(reg);
		masm.regAlloc.unfree(reg, int.!(state.sp));
	}
	// Pop the top of stack into a register and prepare for it to be overwritten.
	def popRegToOverwrite() -> SpcAbstractVal {
		return popReg(); // XXX: alloc+move when shared
	}
	// Spill a register to its slot(s), if it has been allocated.
	def spillReg(reg: Reg) {
		var slot = masm.regAlloc.get(reg);
		if (slot < 0) return;
		var sv = state.state[slot];
		masm.emit_mov_s_r(u32.!(slot), reg, sv.kind());
		state.state[slot] = SpcAbstractVal(sv.kindFlagsAndTag(IS_STORED), NO_REG, sv.const);
	}
	def setUnreachable() {
		skip_to_end = true;
		state.setUnreachable();
	}
	def traceOpcodeAndStack() {
		OUT.out(Trace.STDOUT);
		OUT.put2("  %x(+%d): ", it.pc, it.pc - start_pos);
		it.trace(OUT, module, instrTracer);
		while (OUT.length < 32) OUT.puts(" ");
		traceStack();
	}
	def traceOpcodeUnreachable() {
		OUT.out(Trace.STDOUT);
		OUT.put2("  %x(+%d): ", it.pc, it.pc - start_pos);
		it.trace(OUT, module, instrTracer);
		while (OUT.length < 32) OUT.puts(" ");
		OUT.puts("...");
		OUT.outln();
	}
	def traceStack() {
		OUT.put1("sp=%d |", state.sp);
		for (i < state.sp) traceAbstractVal(state.state[i]);
		OUT.outln();
	}
	def traceAbstractVal(sv: SpcAbstractVal) {
		match (sv.kind()) {
			I32 => OUT.puts("i");
			I64 => OUT.puts("l");
			F32 => OUT.puts("f");
			F64 => OUT.puts("d");
			V128 => OUT.puts("v");
			REF => OUT.puts("r");
			ABS => OUT.puts("a");
		}
		OUT.put2("%s%s",
			if(sv.tagStored(), "T", ""),
			if(sv.isStored(), "S", ""));
		if (sv.inReg()) OUT.put1("@%s", masm.regAlloc.regConfig.regSet.getName(sv.reg));
		if (sv.isConst()) OUT.put1("=%d", sv.const);
		OUT.puts("|");
	}
}

type SpcReg(reg: Reg, kind: ValueKind) #unboxed { }

type SpcAbstractVal(flags: byte, reg: Reg, const: int) #unboxed {
	def kind() -> ValueKind {
		return SpcConsts.kinds[flags >> 4];
	}
	def kindFlags(add: byte) -> byte {
		return (flags & KIND_MASK) | add;
	}
	def kindFlagsAndTag(add: byte) -> byte {
		return (flags & (KIND_MASK | TAG_STORED)) | add;
	}
	def kindFlagsMatching(kind: ValueKind, add: byte) -> byte {
		var okind = (flags & KIND_MASK);
		var nkind = SpcConsts.kindToFlags(kind);
		if (okind == nkind) nkind |= (flags & TAG_STORED);
		return nkind | add;
	}
	def isStored() -> bool {
		return (flags & IS_STORED) != 0;
	}
	def isConst() -> bool {
		return (flags & IS_CONST) != 0;
	}
	def inReg() -> bool {
		return (flags & IN_REG) != 0;
	}
	def tagStored() -> bool {
		return (flags & TAG_STORED) != 0;
	}
}

type SpcBinopSig(a_kind: ValueKind, b_kind: ValueKind, preserve_flags: byte, add_flags: byte);

def kind_ii_i = SpcBinopSig(ValueKind.I32, ValueKind.I32, KIND_MASK | TAG_STORED, 0);
def kind_ll_l = SpcBinopSig(ValueKind.I64, ValueKind.I64, KIND_MASK | TAG_STORED, 0);
def kind_ll_i = SpcBinopSig(ValueKind.I64, ValueKind.I64, 0, KIND_I32);
def kind_rr_i = SpcBinopSig(ValueKind.REF, ValueKind.REF, 0, KIND_I32);

enum SpcBinop(op: Opcode, commute: Opcode, kind_sig: SpcBinopSig, isNop: int -> bool, fold: (int, int) -> int) {
	I32_ADD		(Opcode.I32_ADD,	Opcode.I32_ADD,		kind_ii_i, isZero, int.+)
	I32_SUB		(Opcode.I32_SUB,	Opcode.UNREACHABLE,	kind_ii_i, isZero, int.-),
	I32_MUL		(Opcode.I32_MUL,	Opcode.I32_MUL,		kind_ii_i, isOne, int.*),
	I32_DIV_S	(Opcode.I32_DIV_S,	Opcode.UNREACHABLE,	kind_ii_i, null, null),
	I32_DIV_U	(Opcode.I32_DIV_U,	Opcode.UNREACHABLE,	kind_ii_i, null, null),
	I32_REM_S	(Opcode.I32_REM_S,	Opcode.UNREACHABLE,	kind_ii_i, null, null),
	I32_REM_U	(Opcode.I32_REM_U,	Opcode.UNREACHABLE,	kind_ii_i, isMinusOne, null),
	I32_AND		(Opcode.I32_AND,	Opcode.I32_AND,		kind_ii_i, isMinusOne, int.&),
	I32_XOR		(Opcode.I32_XOR,	Opcode.I32_XOR,		kind_ii_i, isZero, int.^),
	I32_OR		(Opcode.I32_OR,		Opcode.I32_OR,		kind_ii_i, isZero, int.|),
	I32_SHL		(Opcode.I32_SHL,	Opcode.UNREACHABLE,	kind_ii_i, isZero, V3Eval.I32_SHL),
	I32_SHR_S	(Opcode.I32_SHR_S,	Opcode.UNREACHABLE,	kind_ii_i, isZero, V3Eval.I32_SHR_S),
	I32_SHR_U	(Opcode.I32_SHR_U,	Opcode.UNREACHABLE,	kind_ii_i, isZero, V3Eval.I32_SHR_U),
	I32_ROTL	(Opcode.I32_ROTL,	Opcode.UNREACHABLE,	kind_ii_i, isZero, I32_ROTL),
	I32_ROTR	(Opcode.I32_ROTR,	Opcode.UNREACHABLE,	kind_ii_i, isZero, I32_ROTR),
	I32_EQ		(Opcode.I32_EQ,		Opcode.I32_EQ,		kind_ii_i, null, Fold_ii_i.I32_EQ),
	I32_NE		(Opcode.I32_NE,		Opcode.I32_NE,		kind_ii_i, null, Fold_ii_i.I32_NE),
	I32_LT_S	(Opcode.I32_LT_S,	Opcode.I32_GT_S, 	kind_ii_i, null, Fold_ii_i.I32_LT_S),
	I32_LT_U	(Opcode.I32_LT_U,	Opcode.I32_GT_U, 	kind_ii_i, null, Fold_ii_i.I32_LT_U),
	I32_GT_S	(Opcode.I32_GT_S,	Opcode.I32_LT_S, 	kind_ii_i, null, Fold_ii_i.I32_GT_S),
	I32_GT_U	(Opcode.I32_GT_U,	Opcode.I32_LT_U, 	kind_ii_i, null, Fold_ii_i.I32_GT_U),
	I32_LE_S	(Opcode.I32_LE_S,	Opcode.I32_GE_S, 	kind_ii_i, null, Fold_ii_i.I32_LE_S),
	I32_LE_U	(Opcode.I32_LE_U,	Opcode.I32_GE_U, 	kind_ii_i, null, Fold_ii_i.I32_LE_U),
	I32_GE_S	(Opcode.I32_GE_S,	Opcode.I32_LE_S, 	kind_ii_i, null, Fold_ii_i.I32_GE_S),
	I32_GE_U	(Opcode.I32_GE_U,	Opcode.I32_LE_U, 	kind_ii_i, null, Fold_ii_i.I32_GE_U),

	I64_ADD		(Opcode.I64_ADD,	Opcode.I64_ADD,		kind_ll_l, isZero, null)
	I64_SUB		(Opcode.I64_SUB,	Opcode.UNREACHABLE,	kind_ll_l, isZero, null),
	I64_MUL		(Opcode.I64_MUL,	Opcode.I64_MUL,		kind_ll_l, isOne, null),
	I64_DIV_S	(Opcode.I64_DIV_S,	Opcode.UNREACHABLE,	kind_ll_l, null, null),
	I64_DIV_U	(Opcode.I64_DIV_U,	Opcode.UNREACHABLE,	kind_ll_l, null, null),
	I64_REM_S	(Opcode.I64_REM_S,	Opcode.UNREACHABLE,	kind_ll_l, null, null),
	I64_REM_U	(Opcode.I64_REM_U,	Opcode.UNREACHABLE,	kind_ll_l, isMinusOne, null),
	I64_AND		(Opcode.I64_AND,	Opcode.I64_AND,		kind_ll_l, isMinusOne, null),
	I64_XOR		(Opcode.I64_XOR,	Opcode.I64_XOR,		kind_ll_l, isZero, null),
	I64_OR		(Opcode.I64_OR,		Opcode.I64_OR,		kind_ll_l, isZero, null),
	I64_SHL		(Opcode.I64_SHL,	Opcode.UNREACHABLE,	kind_ll_l, isZero, null),
	I64_SHR_S	(Opcode.I64_SHR_S,	Opcode.UNREACHABLE,	kind_ll_l, isZero, null),
	I64_SHR_U	(Opcode.I64_SHR_U,	Opcode.UNREACHABLE,	kind_ll_l, isZero, null),
	I64_ROTL	(Opcode.I64_ROTL,	Opcode.UNREACHABLE,	kind_ll_l, isZero, null),
	I64_ROTR	(Opcode.I64_ROTR,	Opcode.UNREACHABLE,	kind_ll_l, isZero, null),
	I64_EQ		(Opcode.I64_EQ,		Opcode.I64_EQ,		kind_ll_i, null, null),
	I64_NE		(Opcode.I64_NE,		Opcode.I64_NE,		kind_ll_i, null, null),
	I64_LT_S	(Opcode.I64_LT_S,	Opcode.I64_GT_S, 	kind_ll_i, null, null),
	I64_LT_U	(Opcode.I64_LT_U,	Opcode.I64_GT_U, 	kind_ll_i, null, null),
	I64_GT_S	(Opcode.I64_GT_S,	Opcode.I64_LT_S, 	kind_ll_i, null, null),
	I64_GT_U	(Opcode.I64_GT_U,	Opcode.I64_LT_U, 	kind_ll_i, null, null),
	I64_LE_S	(Opcode.I64_LE_S,	Opcode.I64_GE_S, 	kind_ll_i, null, null),
	I64_LE_U	(Opcode.I64_LE_U,	Opcode.I64_GE_U, 	kind_ll_i, null, null),
	I64_GE_S	(Opcode.I64_GE_S,	Opcode.I64_LE_S, 	kind_ll_i, null, null),
	I64_GE_U	(Opcode.I64_GE_U,	Opcode.I64_LE_U, 	kind_ll_i, null, null)

	REF_EQ		(Opcode.REF_EQ,		Opcode.REF_EQ,		kind_rr_i, null, null),
}

// An entry in the abstract control stack.
class SpcControl {
	var opcode: byte;
	var params: Array<ValueType>;
	var results: Array<ValueType>;
	var reachable = true;
	var val_stack_top: u32;
	var label: MasmLabel;
	var else_label: MasmLabel;
	// the state at the merge (label)
	var merge_count: byte;
	var merge_state: Array<SpcAbstractVal>;
	// the state used to reset back to before the true branch of an if
	var reset_state: Array<SpcAbstractVal>;

	def clearMerge() {
		merge_count = 0;
		merge_state = null;
	}
	def clearReset() {
		reset_state = null;
	}
}

def isZero = int.==(0, _);
def isOne = int.==(1, _);
def isNotZero = int.!=(0, _);
def trueToOne(z: bool) -> int { return if(z, 1, 0); }
def isMinusOne = int.==(-1, _);
def to_ii_i(f: (u32, u32) -> u32, a: int, b: int) -> int {
	return int.view(f(u32.view(a), u32.view(b)));
}
def i32_unsigned_to_i64(i: i32) -> i64 { return i64.view(u32.view(i)); }
def I32_ROTL = to_ii_i(V3Eval.I32_ROTL, _, _);
def I32_ROTR = to_ii_i(V3Eval.I32_ROTR, _, _);

// Contains both the abstract control and abstract value stack.
class SpcAbstractState(regAlloc: RegAlloc) {
	// Abstract state of the value stack
	var state = Array<SpcAbstractVal>.new(INITIAL);
	var sp: u32;
	var ctl_stack = ArrayStack<SpcControl>.new();
	var num_locals: u16;

	// Reset the state for starting a new function.
	def reset(sig: SigDecl, ret_label: MasmLabel) {
		sp = 0;
		ctl_stack.clear();
		// manually set up first control entry and return merge state
		var results = sig.results;
		var ctl = pushControl(Opcode.RETURN.code, ValueTypes.NONE, results, ret_label);
		var merge_state = Array<SpcAbstractVal>.new(results.length);
		for (i < results.length) {
			// request the merged values be stored to the stack, but don't require tags
			merge_state[i] = SpcAbstractVal(typeToKindFlags(results[i]) | IS_STORED, NO_REG, 0);
		}
		ctl.merge_state = merge_state;
		ctl.merge_count = 1;
		// initialize parameters
		var params = sig.params;
		grow(params.length);
		for (i < params.length) {
			// params start on the stack and already have tags
			state[i] = SpcAbstractVal(typeToKindFlags(params[i]) | TAG_STORED | IS_STORED, NO_REG, 0);
		}
		sp = u32.view(params.length);
	}
	// Add the specified number of locals of the specified type.
	def addLocals(count: u32, ltype: ValueType) {
		var nlength = sp + count;
		if (nlength > state.length) grow(int.view(nlength + sp * 2));
		var flags = typeToKindFlags(ltype) | TAG_STORED | IS_CONST; // TODO: store tag of locals
		for (j < count) {
			var k = j + sp;
			state[k] = SpcAbstractVal(flags, NO_REG, 0);
		}
		sp = nlength;
	}
	def pushBlock(params: Array<ValueType>, results: Array<ValueType>, end_label: MasmLabel) -> SpcControl {
		return pushControl(Opcode.BLOCK.code, params, results, end_label);
	}
	def pushLoop(params: Array<ValueType>, results: Array<ValueType>, start_label: MasmLabel) -> SpcControl {
		var ctl = pushControl(Opcode.LOOP.code, params, results, start_label);
		return ctl;
	}
	def prepareLoop(emitSlotTransfer: ((u32, SpcAbstractVal), (u32, SpcAbstractVal)) -> void) {
		var target = ctl_stack.peek();
		target.merge_count = 1;
		target.merge_state = Arrays.range(state, 0, int.view(sp));
		for (i < sp) {
			var from = state[i], to = toMergeVal(from);
			target.merge_state[i] = to;
			state[i] = to;
			if (from != to) emitSlotTransfer((i, to), (i, from));
		}
	}
	def pushIf(params: Array<ValueType>, results: Array<ValueType>, else_label: MasmLabel, end_label: MasmLabel) -> SpcControl {
		var ctl = pushControl(Opcode.IF.code, params, results, end_label);
		ctl.else_label = else_label;
		ctl.reset_state = Arrays.dup(state);
		return ctl;
	}
	def doElse() {
		var c = ctl_stack.peek();
		c.else_label = null;
		// reset state to start of if
		var max = c.val_stack_top + u32.view(c.params.length);
		resetTo(max, c.reset_state);
		c.clearReset();
		if (ctl_stack.top > 1) c.reachable = ctl_stack.elems[ctl_stack.top - 2].reachable;
		else c.reachable = true;
	}
	def resetToMerge(ctl: SpcControl) {
		if (ctl.merge_count > 0) {
			var max = ctl.val_stack_top + u32.view(ctl.results.length);
			resetTo(max, ctl.merge_state);
		} else {
			// merge not reached; push "bottom" value for all results
			sp = ctl.val_stack_top;
			for (r in ctl.results) {
				push(typeToKindFlags(r) | IS_STORED | TAG_STORED | IS_CONST, NO_REG, 0);
			}
			
		}
	}
	def isTransferEmpty(target: SpcControl) -> bool {
		return false; // XXX: approximate
	}
	def emitFallthru(emitSlotTransfer: ((u32, SpcAbstractVal), (u32, SpcAbstractVal)) -> void) {
		emitTransfer(ctl_stack.peek(), emitSlotTransfer);
	}
	def emitTransfer(target: SpcControl, emitSlotTransfer: ((u32, SpcAbstractVal), (u32, SpcAbstractVal)) -> void) {
		if (!ctl_stack.peek().reachable) {
			if (Trace.compiler) OUT.puts("    xfer not reachable").outln();
			return; // do nothing
		}
		if (Trace.compiler) OUT.put1("    xfer -> sp=%d", target.val_stack_top).outln();
		var vals = u32.view(if(target.opcode == Opcode.LOOP.code, target.params, target.results).length);
		var top = target.val_stack_top, max = top + vals;
		if (target.merge_count == 0) {
			if (Trace.compiler) OUT.puts("    merge_count=1").outln();
			target.merge_count = 1;
			target.merge_state = Arrays.range(state, 0, int.view(max));
			for (i < top) {
				var from = state[i], to = toMergeVal(from);
				target.merge_state[i] = to;
				if (from != to) emitSlotTransfer((i, to), (i, from));
			}
			for (i < vals) {
				var f = (sp - vals + i), t = top + i;
				var from = state[f], to = toMergeVal(from);
				target.merge_state[t] = to;
				emitSlotTransfer((t, to), (f, from));
			}
		} else {
			if (Trace.compiler) OUT.puts("    merge_count=2+").outln();
			target.merge_count = 2;
			// XXX: allow matching constants in merges
			for (i < top) {
				var from = state[i], to = target.merge_state[i];
				if (from != to) emitSlotTransfer((i, to), (i, from));
			}
			for (i < vals) {
				var f = (sp - vals + i), t = top + i;
				var from = state[f], to = target.merge_state[t];
				// TODO: write tag based on mismatch on this stack's target slot
				emitSlotTransfer((t, to), (f, from));
			}
		}
	}
	def emitKill(emitSlotTransfer: ((u32, SpcAbstractVal), (u32, SpcAbstractVal)) -> void) {
		if (Trace.compiler) OUT.puts("    kill all").outln();
		for (i < sp) {
			var sv = state[i], oflags = sv.flags;
			if ((oflags & IN_REG) != 0) regAlloc.free(sv.reg);
			var stored = IS_STORED | TAG_STORED;
			var nflags = (oflags & ~IN_REG) | stored;
			var nv = SpcAbstractVal(nflags, NO_REG, sv.const);
			state[i] = nv;
			if (stored == (oflags & stored)) continue;
			var slot = u32.view(i);
			emitSlotTransfer((slot, nv), (slot, sv));
		}
	}
	private def toMergeVal(from: SpcAbstractVal) -> SpcAbstractVal {
		// XXX: allow constants in merges
		var force_store = if(!from.inReg(), IS_STORED);
		return SpcAbstractVal((from.flags & ~(IS_CONST)) | force_store, from.reg, 0);
	}
	private def resetTo(max: u32, nstate: Array<SpcAbstractVal>) {
		regAlloc.clear();
		for (i < max) {
			var sv = nstate[i];
			if (sv.inReg()) regAlloc.unfree(sv.reg, int.!(i));
			state[i] = sv;
		}
		sp = max;
	}
	private def pushControl(opcode: byte, params: Array<ValueType>, results: Array<ValueType>, label: MasmLabel) -> SpcControl {
		var ctl = ctl_stack.next();
		var reachable = if(ctl_stack.top > 0, ctl_stack.peek().reachable, true);
		if (ctl != null) { // FAST: reuse previous SpcControl object
			ctl_stack.top++;
			ctl.clearMerge();
			ctl.clearReset();
			ctl.else_label = null;
		} else { // allocate and cache new SpcControl object
			ctl = SpcControl.new();
			ctl_stack.push(ctl);
		}
		ctl.opcode = opcode;
		ctl.label = label;
		ctl.params = params;
		ctl.results = results;
		ctl.val_stack_top = sp - u32.view(params.length);
		ctl.reachable = reachable;
		ctl.merge_count = 0;
		return ctl;
	}
	def getControl(depth: u32) -> SpcControl {
		var result = ctl_stack.elems[ctl_stack.top - int.!(depth) - 1];
		return result;
	}
	def push(flags: byte, reg: Reg, const: int) {
		var sp = this.sp;
		if (sp >= state.length) grow(8 + state.length * 2);
		state[sp] = SpcAbstractVal(flags, reg, const);
		this.sp++;
	}
	def pushV(v: SpcAbstractVal) {
		var sp = this.sp;
		if (sp >= state.length) grow(8 + state.length * 2);
		state[sp] = v;
		this.sp++;
	}
	def get(slot: u32) -> SpcAbstractVal {
		return state[slot];
	}
	def pop() -> SpcAbstractVal {
		if (sp == 0) {
// TODO			err.at(codeptr).set("stack underflow");
			var d: SpcAbstractVal;
			return d;
		}
		var result = state[--this.sp];
		return result;
	}
	def popArgsAndPushResults(sig: SigDecl) {
		sp -= u32.view(sig.params.length); // note: assume registers have been freed
		for (t in sig.results) {
			push(typeToKindFlags(t) | TAG_STORED | IS_STORED, NO_REG, 0);
		}
	}
	def peek() -> SpcAbstractVal {
		return state[sp - 1];
	}
	def peek2() -> (SpcAbstractVal, SpcAbstractVal) {
		return (state[sp - 2], state[sp - 1]);
	}
	def overwrite(flags: byte, reg: Reg, const: int) {
		var old = state[sp - 1];
		var tag_stored = if((old.flags & KIND_MASK) == (flags & KIND_MASK), old.flags & TAG_STORED);
		state[sp - 1] = SpcAbstractVal(tag_stored | flags, reg, const);
	}
	def set(slot: u32, flags: byte, reg: Reg, const: int) {
		state[slot] = SpcAbstractVal(flags, reg, const);
	}
	def setStored(slot: u32) {
		var b = state[slot];
		state[slot] = SpcAbstractVal(b.flags | IS_STORED, b.reg, b.const);
	}
	def setUnreachable() {
		ctl_stack.peek().reachable = false;
	}
	def setNoReg(slot: u32) {
		var b = state[slot];
		state[slot] = SpcAbstractVal(b.flags & ~IN_REG, NO_REG, b.const);
	}
	def grow(nlength: int) {
		state = Arrays.grow(state, nlength);
	}
}
def toTag(vt: ValueType) -> ValueKind {
	match (vt) {
		I32 => return ValueKind.I32;
		I64 => return ValueKind.I64;
		F32 => return ValueKind.F32;
		F64 => return ValueKind.F64;
		V128 => return ValueKind.V128;
		_ => return ValueKind.REF;
	}
}
def typeToKindFlags(vt: ValueType) -> byte {
	match (vt) {
		I32 => return KIND_I32;
		I64 => return KIND_I64;
		F32 => return KIND_F32;
		F64 => return KIND_F64;
		V128 => return KIND_V128;
		_ => return KIND_REF;
	}
}
// Specialized routines that work on i32, rather than values.
component Fold_ii_i {
	private def do_ii_z(f: (int, int) -> bool, a: int, b: int) -> int {
		return if(f(a, a), 1);
	}
	private def do_uu_z(f: (u32, u32) -> bool, a: int, b: int) -> int {
		return if(f(u32.view(a), u32.view(b)), 1);
	}
	def I32_EQ = do_ii_z(int.==, _, _);
	def I32_NE = do_ii_z(int.!=, _, _);
	def I32_LT_S = do_ii_z(int.<, _, _);
	def I32_LT_U = do_uu_z(u32.<, _, _);
	def I32_GT_S = do_ii_z(int.>, _, _);
	def I32_GT_U = do_uu_z(u32.>, _, _);
	def I32_LE_S = do_ii_z(int.<=, _, _);
	def I32_LE_U = do_uu_z(u32.<=, _, _);
	def I32_GE_S = do_ii_z(int.>=, _, _);
	def I32_GE_U = do_uu_z(u32.>=, _, _);
}
