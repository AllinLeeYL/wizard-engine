// Copyright 2021 Ben L. Titzer. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

def RT: X86_64Runtime;
// Contains target-specific factory functions.
component Target {
	def V3_PARAM_GPRS = [X86_64Regs.RDI, X86_64Regs.RSI, X86_64Regs.RDX, X86_64Regs.RCX, X86_64Regs.R8, X86_64Regs.R9]; 		// System-V
	def V3_RET_GPRS = [X86_64Regs.RAX, X86_64Regs.RDX, X86_64Regs.RCX, X86_64Regs.RSI]; 			// System-V + 2

	def limit_memory_pages = 65536u;
	def newMemory = X86_64Memory.new;
	def forceGC = RiGc.forceGC;
	def tuning = X86_64InterpreterTuning.new();
	def tagging = Tagging.new(tuning.taggedValues, tuning.simdSupport);

	new() {
		ExecuteOptions.registerMode("jit", X86_64SpcAotStrategy.new(),
			"ahead-of-time compile entire module with SPC");
//TODO		ExecuteOptions.registerMode("lazy", X86_64SpcLazyStrategy.new(), "lazy-compile functions on demand with SPC");
//TODO		ExecuteOptions.registerMode("dyn", X86_64DynamicStrategy.new(), "fast interpreter with dynamic tier-up to SPC");
//TODO		ExecuteOptions.registerMode("mixed", X86_64MixedStrategy.new(), "lazy-compile functions on demand with SPC, fallback to fast-int");
		ExecuteOptions.registerDefaultMode("int", X86_64InterpreterOnlyStrategy.new(),
			"fast interpreter only");
		Execute.probes.onEnable = X86_64Interpreter.onProbeEnable;
		Execute.probes.onDisable = X86_64Interpreter.onProbeDisable;
	}

	// A handy chokepoint for setting breakpoints in debugging.
	def setTargetCode(f: FuncDecl, addr: Pointer) {
		f.target_code = TargetCode(addr);
	}
	def genInterpreterIntoFile(filename: string) -> ErrorBuilder {
		var data = System.fileLoad(filename);
		var err = ErrorBuilder.new().puts("interpreter generator: ");
		if (data == null) return err.put1("could not load executable %s\n", filename);
		var ok = X86_64Interpreter.serializeInterpreterCodeIntoExecutable(data);
		if (ok == false) return err.put1("could not patch executable %s\n", filename);
		var fd = System.fileOpen(filename, false);
		if (fd < 0) return err.put1("could not write executable: %s\n", filename);
		System.fileWriteK(fd, data, 0, data.length);
		System.fileClose(fd);
		return null;
	}
	def mapCode(asm: X86_64Assembler, prepare: (X86_64Assembler, u64) -> void) -> Mapping {
		var w = asm.w;
		var length = u64.view(w.atEnd().pos);
		var mapping = Mmap.reserve(length, Mmap.PROT_WRITE), range = mapping.range;
		if (prepare != null) prepare(asm, u64.view(range.start - Pointer.NULL));
		var t = range.start;
		var f = Pointer.atContents(w.data);
		for (i = 0; i < length; i += Pointer.SIZE) { // XXX: manual memcopy
			t.store<Pointer>(f.load<Pointer>());
			t += Pointer.SIZE;
			f += Pointer.SIZE;
		}
		Mmap.protect(range.start, u64.!(range.end - range.start), Mmap.PROT_READ | Mmap.PROT_EXEC);
		return mapping;
	}
	def copyInto(range: MemoryRange, offset: int, w: DataWriter) -> int {
		var t = range.start + offset;
		var f = Pointer.atContents(w.data);
		var length = w.atEnd().pos;
		for (i = 0; i < length; i += Pointer.SIZE) { // XXX: manual memcopy
			t.store<Pointer>(f.load<Pointer>());
			t += Pointer.SIZE;
			f += Pointer.SIZE;
		}
		return offset + length;
	}
}

type TargetCode(spc_entry: Pointer) #unboxed { }
type TargetModule(spc_code: X86_64SpcCode) #unboxed { }
type TargetFrame(sp: Pointer) #unboxed {
	def getFrameAccessor() -> FrameAccessor {
		return RT.getFrameAccessor(sp);
	}
}

// One tier: fast-int, modules require no pre-processing.
class X86_64InterpreterOnlyStrategy extends ExecutionStrategy {
	// Call a function with arguments and return a result.
	def call(func: Function, args: Array<Value>) -> Result {
		if (X86_64Interpreter.interpreterCode == null) X86_64Interpreter.genInterpreterCode();
		return X86_64Runtime.run(func, args); // XXX: specialize for interpreter-only
	}
}

// One tier: SPC, modules are eagerly compiled.
class X86_64SpcAotStrategy extends ExecutionStrategy {
	var hasMonitors = false;

	// Called if monitors will be attached to the (forthcoming) module.
	def onMonitorsStart() {
		hasMonitors = true;
	}
	// Called after a module is parsed.
	def onModuleFinish(module: Module, size: u32, err: ErrorGen) {
		// defer compilation for AOT mode until after monitors have been installed
		if (!hasMonitors) compileEntireModule(module, size, err);
	}
	// Called after monitors have processed a module.
	def onMonitorsFinish(module: Module, err: ErrorGen) {
		compileEntireModule(module, 0, err);
	}
	// Called before a test function is run.
	def onTestRun(wf: WasmFunction, err: ErrorGen) {
		if (wf.decl.target_code.spc_entry == Pointer.NULL) {
			compileEntireModule(wf.instance.module, 0, err); // XXX: compile individual functions in test
		}
	}
	// Call a function with arguments and return a result.
	def call(func: Function, args: Array<Value>) -> Result {
		return X86_64Runtime.run(func, args); // XXX: specialize for JIT-only, do lazy compile
	}
	private def compileEntireModule(module: Module, size: u32, err: ErrorGen) {
		// ensure entrypoint and lazy compile stubs are generated
		X86_64Spc.genStubs(null);

		var extensions = Extension.set.all; // TODO: all extensions enabled for compilation
		var limits = Limits.new();
		// TODO: ignore bailouts for non-AOT mode
		var compiler = X86_64SinglePassCompiler.new(extensions, limits, X86_64Regs2.CONFIG, err);
		var w = compiler.w;

		// generate code for all functions
		var starts = Array<int>.new(module.functions.length);
		for (i = 0; err.ok() && i < module.functions.length; i++) { // TODO: graceful bailouts
			var f = module.functions[i];
			if (f.imported()) continue;
			starts[i] = w.atEnd().pos;
			var compiled = compiler.gen(module, f);
			if (!compiled) starts[i] = -1;
		}
		// emit handlers for signal-generated traps
		var masm = X86_64MacroAssembler.!(compiler.masm);
		var oobMemoryHandlerLabel = masm.newTrapLabel(TrapReason.MEM_OUT_OF_BOUNDS);
		var divZeroHandlerLabel = masm.newTrapLabel(TrapReason.DIV_BY_ZERO);
		var stackOverflowHandlerLabel = masm.newTrapLabel(TrapReason.STACK_OVERFLOW);

		// emit shared sequences for all trap returns
		// XXX: share trap return sequences across all modules
		for (reason in TrapReason) {
			var label = masm.getTrapLabel(reason);
			if (label != null) compiler.emitTrapReturn(label, reason);
		}

		// copy and map code
		var length = u64.view(w.atEnd().pos);
		var mapping = Mmap.reserve(length, Mmap.PROT_WRITE), range = mapping.range; // TODO: handle failure
		masm.setTargetAddress(u64.view(range.start - Pointer.NULL));
		Target.copyInto(mapping.range, 0, w);
		Mmap.protect(range.start, u64.!(range.end - range.start), Mmap.PROT_READ | Mmap.PROT_EXEC);
		for (i < starts.length) {
			if (starts[i] >= 0) {
				var addr = mapping.range.start + starts[i];
				if (Trace.compiler) Trace.OUT.put2("func[%d].spc_entry: break *0x%x", i, addr - Pointer.NULL).outln();
				Target.setTargetCode(module.functions[i], addr);
			}
		}
		var code = X86_64SpcCode.new(mapping);
		code.oobMemoryHandlerOffset = oobMemoryHandlerLabel.offset;
		code.divZeroHandlerOffset = divZeroHandlerLabel.offset;
		code.stackOverflowHandlerOffset = stackOverflowHandlerLabel.offset;

		module.target_module = TargetModule(code);
		RiRuntime.registerUserCode(code);
		module.target_module.spc_code.keepAlive();
	}
}

// One tier: SPC, functions are lazily compiled.
class X86_64SpcLazyStrategy extends ExecutionStrategy {
	// Called after a module is parsed.
	def onModuleFinish(module: Module, size: u32, err: ErrorGen) {
		installLazyCompileStubForModule(module, err);
	}
	// Called before a test function is run.
	def onTestRun(wf: WasmFunction, err: ErrorGen) {
		installLazyCompileStubForModule(wf.instance.module, err);
	}
	// Call a function with arguments and return a result.
	def call(func: Function, args: Array<Value>) -> Result {
		return X86_64Runtime.run(func, args); // XXX: specialize for JIT-only, do lazy compile
	}
	private def installLazyCompileStubForModule(module: Module, err: ErrorGen) {
		// ensure entrypoint and lazy compile stubs are generated
		X86_64Spc.genStubs(lazyCompile);
		// Estimate code space for the entire module.
		var codeSize = 4096 + 4096;
		// Set all functions to refer to the lazy compile stub.
		for (i = 0; err.ok() && i < module.functions.length; i++) {
			var f = module.functions[i];
			if (f.imported()) continue;
			X86_64Spc.setLazyCompileFor(f);
			codeSize += X86_64Spc.estimateCodeSizeFor(f);
		}
		// Allocate a read/write/execute mapping for code.
		var mapping = Mmap.reserve(u64.!(codeSize), Mmap.PROT_WRITE | Mmap.PROT_READ | Mmap.PROT_EXEC);
		var code = X86_64SpcCode.new(mapping);
		module.target_module = TargetModule(code);
		RiRuntime.registerUserCode(code);
		code.keepAlive();
		// TODO: compile the trap reason labels onto the last page.
//		var oobMemoryHandlerLabel = masm.newTrapLabel(TrapReason.MEM_OUT_OF_BOUNDS);
//		var divZeroHandlerLabel = masm.newTrapLabel(TrapReason.DIV_BY_ZERO);
//		var stackOverflowHandlerLabel = masm.newTrapLabel(TrapReason.STACK_OVERFLOW);
	}
	private def lazyCompile(wf: WasmFunction) -> (WasmFunction, Pointer) {
		var module = wf.instance.module;
		var code = module.target_module.spc_code;
		// XXX: cache the compiler across lazy compiles
		var extensions = Extension.set.all; // TODO: all extensions enabled for compilation
		var limits = Limits.new();
		var err = ErrorGen.new(module.filename);
		var compiler = X86_64SinglePassCompiler.new(extensions, limits, X86_64Regs2.CONFIG, err);

		// generate code for the function
		compiler.gen(module, wf.decl);

		// Check for remaining code space
		var masm = X86_64MacroAssembler.!(compiler.masm), w = masm.asm.w;
		w.align(8);
		var regionSize = code.mapping.range.end - code.mapping.range.start;
		var remaining = regionSize - code.codeEnd;
		var codeSize = w.atEnd().pos;
		if (codeSize > remaining) err.abs(0).set(
			Strings.format3("exhausted code space for module (%d of %d bytes remaining, need %d)",
				remaining, regionSize, codeSize));

		// Check for any errors
		if (err.error()) return X86_64Spc.returnCompileFailed(wf, err);

		// Copy code into end of region
		var range = code.mapping.range;
		var spc_entry = range.start + code.codeEnd;
		masm.setTargetAddress(u64.view(spc_entry - Pointer.NULL));
		code.codeEnd = Target.copyInto(range, code.codeEnd, w);

		Target.setTargetCode(wf.decl, spc_entry);
		if (Trace.compiler) Trace.OUT.put2("func[%d].spc_entry: break *0x%x", wf.decl.func_index, spc_entry - Pointer.NULL).outln();
		return (wf, spc_entry);
	}
}