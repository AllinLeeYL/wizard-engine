// Copyright 2022 Ben L. Titzer. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// XXX: reduce duplication with MacroAssembler
def G = X86_64Regs2.toGpr, X = X86_64Regs2.toXmmr;
def R: X86_64Regs;
def C: X86_64Conds;
def A(ma: MasmAddr) -> X86_64Addr {
	return X86_64Addr.new(G(ma.base), null, 1, ma.offset);
}

// Shorten constants inside this file.
def NO_REG = SpcConsts.NO_REG;
def IS_STORED = SpcConsts.IS_STORED;
def IS_CONST = SpcConsts.IS_CONST;
def IN_REG = SpcConsts.IN_REG;
def TAG_STORED = SpcConsts.TAG_STORED;
def KIND_MASK = SpcConsts.KIND_MASK;
def KIND_I32 = SpcConsts.KIND_I32;
def KIND_I64 = SpcConsts.KIND_I64;
def KIND_F32 = SpcConsts.KIND_F32;
def KIND_F64 = SpcConsts.KIND_F64;
def KIND_V128 = SpcConsts.KIND_V128;
def KIND_REF = SpcConsts.KIND_REF;
def KIND_ABS = SpcConsts.KIND_ABS;

class X86_64SinglePassCompiler extends SinglePassCompiler {
	def w = DataWriter.new();
	def mmasm = X86_64MacroAssembler.new(w, X86_64Regs2.SPC_ALLOC.copy());
	def asm = mmasm.asm;

	new(extensions: Extension.set, limits: Limits, config: RegConfig, module: Module)
		super(mmasm, extensions, limits, module) {
	}
	def visitReinterpret(kind: ValueKind, flags: byte) {
		var sv = state.pop();
		if (sv.isConst()) {
			state.push(flags | IS_CONST, NO_REG, sv.const);
		} else if (sv.inReg()) {
			var d = allocReg(kind);
			match (kind) {
				I32 => asm.movd_r_s(G(d.reg), X(sv.reg));
				I64 => asm.movq_r_s(G(d.reg), X(sv.reg));
				F32 => asm.movd_s_r(X(d.reg), G(sv.reg));
				F64 => asm.movq_s_r(X(d.reg), G(sv.reg));
				_ => bailout("unexpected value kind");
			}
			state.push(flags | IN_REG, d.reg, 0);
			freeVal(sv);
		} else {
			state.push(flags | IS_STORED, NO_REG, 0);
		}
	}
	def visit_I32_REINTERPRET_F32() {
		visitReinterpret(ValueKind.I32, KIND_I32);
	}
	def visit_I64_REINTERPRET_F64() {
		visitReinterpret(ValueKind.I64, KIND_I64);
	}
	def visit_F32_REINTERPRET_I32() {
		visitReinterpret(ValueKind.F32, KIND_F32);
	}
	def visit_F64_REINTERPRET_I64() {
		visitReinterpret(ValueKind.F64, KIND_F64);
	}
	/* TODO:
	def visit_I64_EXTEND_I32_U() {
		if (tryMaybeFold1(ValueKind.I64, V3FoldI32.I64_EXTEND_I32_U)) return;
		var sv = popReg(), r = G(sv.reg);
		asm.movd_r_r(r, r);
		state.push(KIND_I64 | IN_REG, sv.reg, 0);
	}
	def visit_I64_EXTEND_I32_S() {
		if (tryFold1(ValueKind.I64, i32.view<i32>)) return;
		var sv = popReg(), r = G(sv.reg);
		asm.q.shl_r_i(r, 32);
		asm.q.sar_r_i(r, 32);
		state.push(KIND_I64 | IN_REG, sv.reg, 0);
	}
	*/
}

def ucontext_rip_offset = 168;
def ucontext_rsp_offset = 160;
def SIGFPE  = 8;
def SIGBUS  = 10;
def SIGSEGV = 11;

// Implements the RiUserCode interface to add generated machine code to the V3 runtime.
// Handles stackwalking and signals in JITed code.
class X86_64SpcCode extends RiUserCode {
	def mapping: Mapping;
	def frameSize = IVarConfig.frameSize;
	var oobMemoryHandlerOffset: int;	// handler for signals caused by OOB memory access
	var divZeroHandlerOffset: int;		// handler for signals caused by divide by zero
	var stackOverflowHandlerOffset: int;	// handler for signals caused by (value- or call-) stack overflow
	var buf = StringBuilder.new().grow(128);  // avoid allocations when describing frames

	new(mapping) super(mapping.range.start, mapping.range.end) { }

	// Called from V3 runtime upon fatal errors to describe a frame for a stacktrace.
	def describeFrame(ip: Pointer, sp: Pointer, out: (Array<byte>, int, int) -> ()) {
		var msg = "\tin [spc-jit] ";
		out(msg, 0, msg.length);
		var instance = (sp + IVarConfig.frame.INSTANCE.disp).load<Instance>();
		var func = (sp + IVarConfig.frame.FUNC_DECL.disp).load<FuncDecl>();
		// TODO: lazy parse of names section may allocate; must avoid this in OOM situation
		func.render(instance.module.names, buf);
		buf.ln().out(out);
		buf.reset();
	}

	// Called from V3 runtime for a frame where {ip} is in interpreter code.
	def nextFrame(ip: Pointer, sp: Pointer) -> (Pointer, Pointer) {
		sp += frameSize;	 // assume frame is allocated
		ip = sp.load<Pointer>(); // return address on stack
		return (ip + -1, sp + Pointer.SIZE); // XXX: V3 quirk with -1 (use RiOs?)
	}

	// Called from V3 runtime when the garbage collector needs to scan a JIT stack frame.
	def scanFrame(ip: Pointer, sp: Pointer) {
		// Handle other roots in the frame
		RiGc.scanRoot(sp + IVarConfig.frame.FUNC_DECL.disp);
		RiGc.scanRoot(sp + IVarConfig.frame.INSTANCE.disp);
	}

	// Called from V3 runtime to handle an OS-level signal that occurred while {ip} was in JIT code.
	def handleSignal(signum: int, siginfo: Pointer, ucontext: Pointer, ip: Pointer, sp: Pointer) -> bool {
		var pip = ucontext + ucontext_rip_offset;
		var ip = pip.load<Pointer>();
		if (Trace.interpreter) {
			Trace.OUT.put2("  !signal %d in JIT code @ 0x%x", signum, ip - Pointer.NULL).outln();
		}
		match (signum) {
			SIGFPE => {
				// presume divide/modulus by zero
				pip.store<Pointer>(start + divZeroHandlerOffset);
				return true;
			}
			SIGBUS, SIGSEGV => {
				var addr = RiOs.getAccessAddress(siginfo, ucontext);
				if (RedZones.isInRedZone(addr)) {
					pip.store<Pointer>(start + stackOverflowHandlerOffset);
					return true;
				}
				pip.store<Pointer>(start + oobMemoryHandlerOffset);
				return true;
			}
		}
		return true;
	}
	def keepAlive() { // XXX: need to trick V3 whole-program optimizer to not delete these fields
		if (mapping == null) System.error(null, null);
		if (mapping.range == null) System.error(null, null);
	}
}
